# advanced_technical_analysis.py (ì™„ì „ ìˆ˜ì • ë²„ì „)
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple
import logging
from scipy.signal import find_peaks, argrelextrema
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

logger = logging.getLogger(__name__)

class AdvancedTechnicalAnalyzer:
    def __init__(self):
        self.fibonacci_levels = [0.236, 0.382, 0.5, 0.618, 0.786]
        
    def analyze_advanced_indicators(self, hist_data: pd.DataFrame) -> Dict[str, Any]:
        """ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ì¢…í•© ë¶„ì„"""
        try:
            if hist_data.empty:
                return {}
            
            results = {}
            
            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            st.write(f"ğŸ“Š ë°ì´í„° ê¸¸ì´: {len(hist_data)}ì¼")
            st.write(f"ğŸ’° ê°€ê²© ë²”ìœ„: ${hist_data['Close'].min():.2f} - ${hist_data['Close'].max():.2f}")
            st.write(f"ğŸ“ˆ ë³€ë™ì„±: {hist_data['Close'].std():.2f}")
            
            # ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ ë¶„ì„ (ê°œì„ ë¨)
            results['elliott_wave'] = self._analyze_elliott_waves_robust(hist_data)
            
            # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚° (ê°œì„ ë¨)
            results['fibonacci_levels'] = self._calculate_fibonacci_levels_robust(hist_data)
            
            # ì°¨íŠ¸ íŒ¨í„´ ì¸ì‹ (ê°œì„ ë¨)
            results['chart_patterns'] = self._detect_chart_patterns_enhanced(hist_data)
            
            # ê³ ê¸‰ ì§€í‘œë“¤
            results['advanced_indicators'] = self._calculate_advanced_indicators(hist_data)
            
            return results
            
        except Exception as e:
            logger.error(f"ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
            st.error(f"ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def _analyze_elliott_waves_robust(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ê°•ê±´í•œ ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ ë¶„ì„"""
        try:
            if len(data) < 30:
                return {
                    'current_wave': 'ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 30ì¼ í•„ìš”)',
                    'wave_count': 0,
                    'trend_direction': 'Neutral',
                    'completion_percentage': 0,
                    'next_target': 0,
                    'confidence': 0.0,
                    'debug_info': f'ë°ì´í„° ê¸¸ì´: {len(data)}ì¼'
                }
            
            prices = data['Close'].values
            
            # ì ì‘ì  íŒŒë¼ë¯¸í„° ì„¤ì •
            data_length = len(prices)
            min_distance = max(2, data_length // 20)  # ë°ì´í„° ê¸¸ì´ì— ë¹„ë¡€
            volatility = np.std(prices)
            prominence = volatility * 0.15  # ë³€ë™ì„±ì˜ 15%
            
            # ê³ ì  ê°ì§€ (ì—¬ëŸ¬ ìŠ¤ì¼€ì¼)
            peaks_short, _ = find_peaks(
                prices, 
                distance=min_distance,
                prominence=prominence
            )
            
            peaks_long, _ = find_peaks(
                prices, 
                distance=min_distance * 2,
                prominence=prominence * 1.5
            )
            
            # ì €ì  ê°ì§€ (ì—¬ëŸ¬ ìŠ¤ì¼€ì¼)
            troughs_short, _ = find_peaks(
                -prices, 
                distance=min_distance,
                prominence=prominence
            )
            
            troughs_long, _ = find_peaks(
                -prices, 
                distance=min_distance * 2,
                prominence=prominence * 1.5
            )
            
            # ë””ë²„ê¹… ì •ë³´
            st.write(f"ğŸ” ê°ì§€ëœ ê³ ì : ë‹¨ê¸° {len(peaks_short)}ê°œ, ì¥ê¸° {len(peaks_long)}ê°œ")
            st.write(f"ğŸ” ê°ì§€ëœ ì €ì : ë‹¨ê¸° {len(troughs_short)}ê°œ, ì¥ê¸° {len(troughs_long)}ê°œ")
            
            # ì „í™˜ì  í†µí•© (ì£¼ìš” ì „í™˜ì  ìš°ì„ )
            all_turning_points = []
            
            # ì¥ê¸° ê³ ì /ì €ì  ë¨¼ì € ì¶”ê°€ (ë” ì¤‘ìš”í•œ ì „í™˜ì )
            for peak in peaks_long:
                all_turning_points.append({
                    'index': peak,
                    'price': prices[peak],
                    'type': 'peak',
                    'importance': 'high'
                })
            
            for trough in troughs_long:
                all_turning_points.append({
                    'index': trough,
                    'price': prices[trough],
                    'type': 'trough',
                    'importance': 'high'
                })
            
            # ë‹¨ê¸° ì „í™˜ì  ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            for peak in peaks_short:
                # ì¥ê¸° ì „í™˜ì ê³¼ ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ì œì™¸
                if not any(abs(peak - tp['index']) < min_distance for tp in all_turning_points):
                    all_turning_points.append({
                        'index': peak,
                        'price': prices[peak],
                        'type': 'peak',
                        'importance': 'medium'
                    })
            
            for trough in troughs_short:
                if not any(abs(trough - tp['index']) < min_distance for tp in all_turning_points):
                    all_turning_points.append({
                        'index': trough,
                        'price': prices[trough],
                        'type': 'trough',
                        'importance': 'medium'
                    })
            
            # ì‹œê°„ìˆœ ì •ë ¬
            all_turning_points.sort(key=lambda x: x['index'])
            
            st.write(f"ğŸ“Š ì´ ì „í™˜ì : {len(all_turning_points)}ê°œ")
            
            if len(all_turning_points) >= 5:
                # ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ íŒ¨í„´ ë¶„ì„
                wave_analysis = self._identify_elliott_pattern_robust(all_turning_points, prices, data)
                return wave_analysis
            else:
                return {
                    'current_wave': f'ì „í™˜ì  ë¶€ì¡± ({len(all_turning_points)}ê°œ)',
                    'wave_count': len(all_turning_points),
                    'trend_direction': 'Insufficient Data',
                    'completion_percentage': 0,
                    'next_target': 0,
                    'confidence': 0.0,
                    'debug_info': f'ì „í™˜ì  {len(all_turning_points)}ê°œ ê°ì§€'
                }
                
        except Exception as e:
            error_msg = f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}'
            st.error(error_msg)
            return {
                'current_wave': error_msg,
                'wave_count': 0,
                'trend_direction': 'Error',
                'completion_percentage': 0,
                'next_target': 0,
                'confidence': 0.0,
                'debug_info': error_msg
            }
    
    def _identify_elliott_pattern_robust(self, turning_points: List[Dict], prices: np.ndarray, data: pd.DataFrame) -> Dict[str, Any]:
        """ê°•ê±´í•œ ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ íŒ¨í„´ ì‹ë³„"""
        try:
            # ìµœê·¼ ì „í™˜ì ë“¤ë¡œ íŒŒë™ ë¶„ì„ (ìµœëŒ€ 8ê°œ)
            recent_points = turning_points[-8:] if len(turning_points) >= 8 else turning_points
            
            # íŒŒë™ ë°©í–¥ ë° ê°•ë„ ë¶„ì„
            start_price = recent_points[0]['price']
            end_price = recent_points[-1]['price']
            price_change = (end_price - start_price) / start_price
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í™•ì¸í•œ ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ íŠ¹ì„± ë°˜ì˜
            # "5íŒŒê°€ 3íŒŒì˜ ê³ ì ì„ ë„˜ì§€ ëª»í•˜ê³  ì¢…ë£Œë˜ëŠ” ê²½ìš°" (ì ˆë‹¨/truncation) ê³ ë ¤
            
            # íŒŒë™ ë¶„ë¥˜ (ì‹¤ì œ ì‹œì¥ íŠ¹ì„± ë°˜ì˜)
            if price_change > 0.08:  # 8% ì´ìƒ ìƒìŠ¹
                if len(recent_points) >= 5:
                    # ìƒìŠ¹ 5íŒŒ íŒ¨í„´ í™•ì¸
                    trend_direction = "ê°•í•œ ìƒìŠ¹ ì¶”ì„¸"
                    current_wave = "ìƒìŠ¹ ì„í„ìŠ¤ íŒŒë™ (1-3-5íŒŒ)"
                    wave_type = "impulse"
                else:
                    trend_direction = "ìƒìŠ¹ ì¶”ì„¸"
                    current_wave = "ìƒìŠ¹ íŒŒë™ ì§„í–‰ ì¤‘"
                    wave_type = "developing"
                    
            elif price_change < -0.08:  # 8% ì´ìƒ í•˜ë½
                if len(recent_points) >= 3:
                    # í•˜ë½ 3íŒŒ íŒ¨í„´ (A-B-C) í™•ì¸
                    trend_direction = "ê°•í•œ í•˜ë½ ì¶”ì„¸"
                    current_wave = "í•˜ë½ ì¡°ì • íŒŒë™ (A-B-CíŒŒ)"
                    wave_type = "corrective"
                else:
                    trend_direction = "í•˜ë½ ì¶”ì„¸"
                    current_wave = "í•˜ë½ íŒŒë™ ì§„í–‰ ì¤‘"
                    wave_type = "developing"
                    
            elif abs(price_change) <= 0.03:  # 3% ì´ë‚´ íš¡ë³´
                trend_direction = "íš¡ë³´ ì¡°ì •"
                current_wave = "ì‚¼ê°í˜• ì¡°ì • íŒŒë™"
                wave_type = "triangle"
            else:
                trend_direction = "ì•½í•œ ì¶”ì„¸"
                current_wave = "ì „í™˜ íŒŒë™"
                wave_type = "transitional"
            
            # íŒŒë™ ì™„ì„±ë„ ê³„ì‚° (ê²€ìƒ‰ ê²°ê³¼ì˜ ì‹¤ì œ ì‚¬ë¡€ ë°˜ì˜)
            if wave_type == "impulse":
                expected_waves = 5  # ìƒìŠ¹ 5íŒŒ
                completion = min(100, (len(recent_points) / expected_waves) * 100)
            elif wave_type == "corrective":
                expected_waves = 3  # í•˜ë½ 3íŒŒ (A-B-C)
                completion = min(100, (len(recent_points) / expected_waves) * 100)
            else:
                expected_waves = 5
                completion = min(100, (len(recent_points) / expected_waves) * 80)
            
            # ë‹¤ìŒ ëª©í‘œê°€ ê³„ì‚° (í”¼ë³´ë‚˜ì¹˜ í™•ì¥ ê¸°ë°˜)
            next_target = self._calculate_elliott_target(recent_points, wave_type, prices)
            
            # íŒŒë™ ì‹ ë¢°ë„ ê³„ì‚° (ì‹¤ì œ íŒ¨í„´ ì¼ì¹˜ë„ ê¸°ë°˜)
            confidence = self._calculate_elliott_confidence(recent_points, wave_type, price_change)
            
            # ì‹œê°„ ë¶„ì„
            time_analysis = self._analyze_wave_timing(recent_points)
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–¸ê¸‰ëœ "êµëŒ€ ì›ì¹™" ë°˜ì˜
            alternation_info = self._check_alternation_principle(recent_points)
            
            return {
                'current_wave': current_wave,
                'wave_count': len(recent_points),
                'trend_direction': trend_direction,
                'completion_percentage': completion,
                'next_target': next_target,
                'wave_type': wave_type,
                'confidence': confidence,
                'price_change_percent': price_change * 100,
                'time_analysis': time_analysis,
                'alternation_info': alternation_info,
                'debug_info': f'ë¶„ì„ ì™„ë£Œ - {len(recent_points)}ê°œ ì „í™˜ì , {wave_type} íŒ¨í„´, ì‹ ë¢°ë„ {confidence:.1%}'
            }
            
        except Exception as e:
            return {
                'current_wave': f'íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}',
                'wave_count': 0,
                'trend_direction': 'Error',
                'completion_percentage': 0,
                'next_target': 0,
                'confidence': 0.0,
                'debug_info': f'íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }
    
    def _calculate_elliott_target(self, turning_points: List[Dict], wave_type: str, prices: np.ndarray) -> float:
        """ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ ëª©í‘œê°€ ê³„ì‚°"""
        try:
            if len(turning_points) < 3:
                return turning_points[-1]['price']
            
            # ìµœê·¼ 3ê°œ ì „í™˜ì ìœ¼ë¡œ ëª©í‘œ ê³„ì‚°
            recent_3 = turning_points[-3:]
            
            if wave_type == "impulse":
                # ìƒìŠ¹ ì„í„ìŠ¤: 1íŒŒ ê¸¸ì´ì˜ 1.618ë°° í™•ì¥
                if len(recent_3) >= 3:
                    wave_1_length = abs(recent_3[1]['price'] - recent_3[0]['price'])
                    target = recent_3[-1]['price'] + (wave_1_length * 1.618)
                else:
                    target = recent_3[-1]['price'] * 1.1
                    
            elif wave_type == "corrective":
                # ì¡°ì • íŒŒë™: 0.618 ë˜ëŒë¦¼ ëª©í‘œ
                high_price = max(tp['price'] for tp in recent_3)
                low_price = min(tp['price'] for tp in recent_3)
                target = high_price - ((high_price - low_price) * 0.618)
                
            else:
                # ê¸°íƒ€: í‰ê·  íšŒê·€
                target = np.mean([tp['price'] for tp in recent_3])
            
            return target
            
        except:
            return turning_points[-1]['price'] if turning_points else 0
    
    def _calculate_elliott_confidence(self, turning_points: List[Dict], wave_type: str, price_change: float) -> float:
        """ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
            
            # ì „í™˜ì  ê°œìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„
            point_count = len(turning_points)
            if point_count >= 5:
                confidence += 0.2
            elif point_count >= 3:
                confidence += 0.1
            
            # íŒŒë™ íƒ€ì…ë³„ ì‹ ë¢°ë„ ì¡°ì •
            if wave_type == "impulse" and point_count >= 5:
                confidence += 0.2  # ì™„ì „í•œ 5íŒŒ íŒ¨í„´
            elif wave_type == "corrective" and point_count >= 3:
                confidence += 0.15  # ì™„ì „í•œ 3íŒŒ íŒ¨í„´
            
            # ê°€ê²© ë³€ë™ ì¼ê´€ì„±
            if abs(price_change) > 0.05:  # 5% ì´ìƒ ëª…í™•í•œ ë°©í–¥ì„±
                confidence += 0.1
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–¸ê¸‰ëœ "ì˜ˆì™¸ê°€ ë§ë‹¤"ëŠ” íŠ¹ì„± ë°˜ì˜
            confidence *= 0.8  # ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ì˜ ì£¼ê´€ì„± ë°˜ì˜
            
            return min(0.9, confidence)  # ìµœëŒ€ 90%ë¡œ ì œí•œ
            
        except:
            return 0.6
    
    def _check_alternation_principle(self, turning_points: List[Dict]) -> str:
        """êµëŒ€ ì›ì¹™ í™•ì¸ (ê²€ìƒ‰ ê²°ê³¼ ë°˜ì˜)"""
        try:
            if len(turning_points) < 4:
                return "êµëŒ€ ì›ì¹™ í™•ì¸ ë¶ˆê°€"
            
            # 2íŒŒì™€ 4íŒŒì˜ êµëŒ€ í™•ì¸
            # "2íŒŒê°€ ê°€íŒŒë¥´ë©´ 4íŒŒëŠ” íš¡ë³´" ì›ì¹™
            
            # ê°„ë‹¨í•œ êµëŒ€ íŒ¨í„´ í™•ì¸
            price_ranges = []
            for i in range(1, len(turning_points)):
                price_range = abs(turning_points[i]['price'] - turning_points[i-1]['price'])
                price_ranges.append(price_range)
            
            if len(price_ranges) >= 2:
                # êµëŒ€ íŒ¨í„´ í™•ì¸
                first_move = price_ranges[0]
                second_move = price_ranges[1]
                
                if abs(first_move - second_move) / max(first_move, second_move) > 0.3:
                    return "êµëŒ€ ì›ì¹™ í™•ì¸ë¨"
                else:
                    return "êµëŒ€ ì›ì¹™ ë¯¸í™•ì¸"
            
            return "êµëŒ€ ì›ì¹™ ë¶„ì„ ì¤‘"
            
        except:
            return "êµëŒ€ ì›ì¹™ ë¶„ì„ ì‹¤íŒ¨"
    
    def _analyze_wave_timing(self, turning_points: List[Dict]) -> Dict[str, Any]:
        """íŒŒë™ ì‹œê°„ ë¶„ì„"""
        try:
            if len(turning_points) < 3:
                return {}
            
            # ì „í™˜ì  ê°„ ì‹œê°„ ê°„ê²© ê³„ì‚°
            time_intervals = []
            for i in range(1, len(turning_points)):
                interval = turning_points[i]['index'] - turning_points[i-1]['index']
                time_intervals.append(interval)
            
            avg_interval = np.mean(time_intervals) if time_intervals else 0
            
            return {
                'average_wave_duration': f"{avg_interval:.0f}ì¼",
                'total_cycle_duration': f"{turning_points[-1]['index'] - turning_points[0]['index']}ì¼",
                'wave_acceleration': "ê°€ì†" if len(time_intervals) > 1 and time_intervals[-1] < time_intervals[0] else "ê°ì†"
            }
            
        except:
            return {}
    
    def _calculate_fibonacci_levels_robust(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ê°•ê±´í•œ í”¼ë³´ë‚˜ì¹˜ ë˜ëŒë¦¼ ë ˆë²¨ ê³„ì‚°"""
        try:
            prices = data['Close']
            
            if len(prices) < 10:
                return {'error': 'ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 10ì¼ í•„ìš”)'}
            
            # ë‹¤ì¤‘ ê¸°ê°„ ë¶„ì„
            results = {}
            periods = []
            
            # ë°ì´í„° ê¸¸ì´ì— ë”°ë¥¸ ì ì‘ì  ê¸°ê°„ ì„¤ì •
            if len(prices) >= 60:
                periods = [20, 30, 60]
            elif len(prices) >= 30:
                periods = [15, 20, 30]
            else:
                periods = [10, 15]
            
            for period in periods:
                if len(prices) >= period:
                    recent_data = prices.tail(period)
                    high = recent_data.max()
                    low = recent_data.min()
                    diff = high - low
                    current_price = prices.iloc[-1]
                    
                    # ìµœì†Œ ë³€ë™ì„± í™•ì¸ (í˜„ì¬ê°€ì˜ 2% ì´ìƒ)
                    if diff > current_price * 0.02:
                        fib_levels = {}
                        for level in self.fibonacci_levels:
                            fib_levels[f'fib_{level}'] = high - (diff * level)
                        
                        # ì§€ì§€/ì €í•­ ë ˆë²¨ ì‹ë³„
                        support_levels = [level for level in fib_levels.values() if level < current_price]
                        resistance_levels = [level for level in fib_levels.values() if level > current_price]
                        
                        results[f'{period}d'] = {
                            'fibonacci_levels': fib_levels,
                            'high': high,
                            'low': low,
                            'current_price': current_price,
                            'nearest_support': max(support_levels) if support_levels else low,
                            'nearest_resistance': min(resistance_levels) if resistance_levels else high,
                            'retracement_percentage': (high - current_price) / diff if diff > 0 else 0,
                            'strength': self._calculate_fib_strength(current_price, fib_levels)
                        }
            
            if results:
                # ê°€ì¥ ì ì ˆí•œ ê¸°ê°„ ì„ íƒ
                primary_key = '30d' if '30d' in results else '20d' if '20d' in results else list(results.keys())[0]
                primary_result = results[primary_key]
                
                st.success(f"âœ… í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚° ì™„ë£Œ: {len(results)}ê°œ ê¸°ê°„ ë¶„ì„")
                
                return {
                    'primary': primary_result,
                    'all_periods': results,
                    'analysis_summary': self._summarize_fibonacci_analysis(results),
                    'status': 'success'
                }
            else:
                return {'error': 'ë³€ë™ì„± ë¶€ì¡± (2% ë¯¸ë§Œ)', 'status': 'insufficient_volatility'}
                
        except Exception as e:
            return {'error': f'ê³„ì‚° ì˜¤ë¥˜: {str(e)}', 'status': 'error'}
    
    def _calculate_fib_strength(self, current_price: float, fib_levels: Dict[str, float]) -> str:
        """í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê°•ë„ ê³„ì‚°"""
        try:
            # í˜„ì¬ê°€ê°€ ì–´ë–¤ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸
            min_distance = float('inf')
            closest_level = None
            
            for level_name, level_value in fib_levels.items():
                distance = abs(current_price - level_value) / current_price
                if distance < min_distance:
                    min_distance = distance
                    closest_level = level_name.split('_')[1]
            
            if min_distance < 0.01:  # 1% ì´ë‚´
                return f"ê°•í•œ {closest_level} ë ˆë²¨"
            elif min_distance < 0.02:  # 2% ì´ë‚´
                return f"ì¤‘ê°„ {closest_level} ë ˆë²¨"
            else:
                return "ì•½í•œ í”¼ë³´ë‚˜ì¹˜ ì‹ í˜¸"
                
        except:
            return "ë¶„ì„ ë¶ˆê°€"
    
    def _summarize_fibonacci_analysis(self, fib_results: Dict) -> str:
        """í”¼ë³´ë‚˜ì¹˜ ë¶„ì„ ìš”ì•½"""
        if not fib_results:
            return "í”¼ë³´ë‚˜ì¹˜ ë¶„ì„ ë°ì´í„° ì—†ìŒ"
        
        # ì£¼ìš” ì§€ì§€/ì €í•­ ë ˆë²¨ ì‹ë³„
        all_supports = []
        all_resistances = []
        
        for period_data in fib_results.values():
            if 'nearest_support' in period_data:
                all_supports.append(period_data['nearest_support'])
            if 'nearest_resistance' in period_data:
                all_resistances.append(period_data['nearest_resistance'])
        
        if all_supports and all_resistances:
            avg_support = np.mean(all_supports)
            avg_resistance = np.mean(all_resistances)
            return f"ì£¼ìš” ì§€ì§€ì„ : ${avg_support:.2f}, ì €í•­ì„ : ${avg_resistance:.2f}"
        else:
            return "í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ë¶„ì„ ì™„ë£Œ"
    
    def _detect_chart_patterns_enhanced(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í–¥ìƒëœ ì°¨íŠ¸ íŒ¨í„´ ì¸ì‹"""
        try:
            patterns = {}
            
            # í—¤ë“œì•¤ìˆ„ë” íŒ¨í„´ (ê°œì„ ë¨)
            patterns['head_and_shoulders'] = self._detect_head_and_shoulders_enhanced(data)
            
            # ì‚¼ê°í˜• íŒ¨í„´ (ê°œì„ ë¨)
            patterns['triangle'] = self._detect_triangle_pattern_enhanced(data)
            
            # ë”ë¸” íƒ‘/ë°”í…€ (ê°œì„ ë¨)
            patterns['double_pattern'] = self._detect_double_pattern_enhanced(data)
            
            # í”Œë˜ê·¸/í˜ë„ŒíŠ¸ íŒ¨í„´
            patterns['flag_pennant'] = self._detect_flag_pennant(data)
            
            # ì›¨ì§€ íŒ¨í„´
            patterns['wedge'] = self._detect_wedge_pattern(data)
            
            # ì±„ë„ íŒ¨í„´
            patterns['channel'] = self._detect_channel_pattern(data)
            
            # ê°ì§€ëœ íŒ¨í„´ ìˆ˜ í‘œì‹œ
            detected_count = sum(1 for p in patterns.values() if p.get('detected', False))
            if detected_count > 0:
                st.success(f"âœ… {detected_count}ê°œ ì°¨íŠ¸ íŒ¨í„´ ê°ì§€")
            
            return patterns
            
        except Exception as e:
            logger.warning(f"ì°¨íŠ¸ íŒ¨í„´ ì¸ì‹ ì‹¤íŒ¨: {e}")
            return {}
    
    def _detect_head_and_shoulders_enhanced(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í–¥ìƒëœ í—¤ë“œì•¤ìˆ„ë” íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values
            
            if len(prices) < 20:
                return {'detected': False, 'reason': 'ë°ì´í„° ë¶€ì¡±'}
            
            # ìµœê·¼ 20ì¼ ë°ì´í„°ë¡œ íŒ¨í„´ ë¶„ì„
            recent_prices = prices[-20:]
            
            # ê³ ì  ê°ì§€
            peaks, _ = find_peaks(
                recent_prices, 
                distance=3,
                prominence=np.std(recent_prices) * 0.3
            )
            
            if len(peaks) >= 3:
                # ìµœê·¼ 3ê°œ ê³ ì  ë¶„ì„
                recent_peaks = peaks[-3:]
                peak_heights = [recent_prices[peak] for peak in recent_peaks]
                
                # í—¤ë“œì•¤ìˆ„ë” ì¡°ê±´ í™•ì¸
                left_shoulder = peak_heights[0]
                head = peak_heights[1]
                right_shoulder = peak_heights[2]
                
                # ì¡°ê±´ í™•ì¸
                head_highest = head > left_shoulder and head > right_shoulder
                shoulder_similar = abs(left_shoulder - right_shoulder) / max(left_shoulder, right_shoulder) < 0.05
                head_prominence = (head - max(left_shoulder, right_shoulder)) / head > 0.03
                
                if head_highest and shoulder_similar and head_prominence:
                    # ëª©ì„  ê³„ì‚°
                    neckline_level = min(recent_prices[recent_peaks[0]:recent_peaks[1]].min(),
                                       recent_prices[recent_peaks[1]:recent_peaks[2]].min())
                    
                    # ëª©í‘œê°€ ê³„ì‚°
                    head_to_neckline = head - neckline_level
                    target_price = neckline_level - head_to_neckline
                    
                    confidence = 0.7 + (0.1 if shoulder_similar else 0) + (0.1 if head_prominence > 0.05 else 0)
                    
                    return {
                        'detected': True,
                        'type': 'Head and Shoulders',
                        'confidence': min(confidence, 0.9),
                        'target_price': target_price,
                        'neckline': neckline_level,
                        'pattern_completion': 85
                    }
            
            return {'detected': False, 'reason': 'íŒ¨í„´ ì¡°ê±´ ë¶ˆì¶©ì¡±'}
            
        except Exception as e:
            return {'detected': False, 'reason': f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}'}
    
    def _detect_triangle_pattern_enhanced(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í–¥ìƒëœ ì‚¼ê°í˜• íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values[-15:]  # ìµœê·¼ 15ì¼
            
            if len(prices) < 10:
                return {'detected': False, 'reason': 'ë°ì´í„° ë¶€ì¡±'}
            
            # ê³ ì ê³¼ ì €ì  ê°ì§€
            peaks, _ = find_peaks(prices, distance=2, prominence=np.std(prices)*0.2)
            troughs, _ = find_peaks(-prices, distance=2, prominence=np.std(prices)*0.2)
            
            if len(peaks) >= 2 and len(troughs) >= 2:
                # ì¶”ì„¸ì„  ê¸°ìš¸ê¸° ê³„ì‚°
                peak_slope = np.polyfit(peaks[-2:], [prices[p] for p in peaks[-2:]], 1)[0]
                trough_slope = np.polyfit(troughs[-2:], [prices[t] for t in troughs[-2:]], 1)[0]
                
                # ì‚¼ê°í˜• íŒ¨í„´ ìœ í˜• íŒë³„
                if peak_slope < -0.05 and trough_slope > 0.05:
                    pattern_type = 'Symmetrical Triangle'
                    confidence = 0.75
                elif peak_slope < -0.05 and abs(trough_slope) < 0.02:
                    pattern_type = 'Descending Triangle'
                    confidence = 0.70
                elif abs(peak_slope) < 0.02 and trough_slope > 0.05:
                    pattern_type = 'Ascending Triangle'
                    confidence = 0.70
                else:
                    return {'detected': False, 'reason': 'ì‚¼ê°í˜• íŒ¨í„´ ë¯¸í˜•ì„±'}
                
                return {
                    'detected': True,
                    'type': pattern_type,
                    'confidence': confidence,
                    'pattern_completion': 70
                }
            
            return {'detected': False, 'reason': 'ì¶©ë¶„í•œ ì „í™˜ì  ì—†ìŒ'}
            
        except Exception as e:
            return {'detected': False, 'reason': f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}'}
    
    def _detect_double_pattern_enhanced(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í–¥ìƒëœ ë”ë¸” íƒ‘/ë°”í…€ íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values[-20:]  # ìµœê·¼ 20ì¼
            
            if len(prices) < 15:
                return {'detected': False, 'reason': 'ë°ì´í„° ë¶€ì¡±'}
            
            # ê³ ì  ê°ì§€
            peaks, _ = find_peaks(prices, distance=5, prominence=np.std(prices)*0.3)
            
            if len(peaks) >= 2:
                last_two_peaks = peaks[-2:]
                peak_heights = [prices[p] for p in last_two_peaks]
                
                # ë‘ ê³ ì ì´ ë¹„ìŠ·í•œ ë†’ì´ì¸ì§€ í™•ì¸
                height_similarity = abs(peak_heights[0] - peak_heights[1]) / max(peak_heights) < 0.03
                time_gap = last_two_peaks[1] - last_two_peaks[0]
                
                if height_similarity and time_gap >= 4:
                    middle_low = np.min(prices[last_two_peaks[0]:last_two_peaks[1]])
                    pattern_height = max(peak_heights) - middle_low
                    target_price = middle_low - pattern_height
                    
                    return {
                        'detected': True,
                        'type': 'Double Top',
                        'confidence': 0.75,
                        'target_price': target_price,
                        'pattern_completion': 80
                    }
            
            # ì €ì  ê°ì§€ (ë”ë¸” ë°”í…€)
            troughs, _ = find_peaks(-prices, distance=5, prominence=np.std(prices)*0.3)
            
            if len(troughs) >= 2:
                last_two_troughs = troughs[-2:]
                trough_depths = [prices[t] for t in last_two_troughs]
                
                depth_similarity = abs(trough_depths[0] - trough_depths[1]) / min(trough_depths) < 0.03
                time_gap = last_two_troughs[1] - last_two_troughs[0]
                
                if depth_similarity and time_gap >= 4:
                    middle_high = np.max(prices[last_two_troughs[0]:last_two_troughs[1]])
                    pattern_height = middle_high - min(trough_depths)
                    target_price = middle_high + pattern_height
                    
                    return {
                        'detected': True,
                        'type': 'Double Bottom',
                        'confidence': 0.75,
                        'target_price': target_price,
                        'pattern_completion': 80
                    }
            
            return {'detected': False, 'reason': 'ë”ë¸” íŒ¨í„´ ì¡°ê±´ ë¶ˆì¶©ì¡±'}
            
        except Exception as e:
            return {'detected': False, 'reason': f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}'}
    
    def _detect_wedge_pattern(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ì›¨ì§€ íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values[-15:]
            
            if len(prices) < 10:
                return {'detected': False}
            
            peaks, _ = find_peaks(prices, distance=2)
            troughs, _ = find_peaks(-prices, distance=2)
            
            if len(peaks) >= 2 and len(troughs) >= 2:
                peak_slope = np.polyfit(peaks[-2:], [prices[p] for p in peaks[-2:]], 1)[0]
                trough_slope = np.polyfit(troughs[-2:], [prices[t] for t in troughs[-2:]], 1)[0]
                
                if peak_slope < 0 and trough_slope < 0 and peak_slope < trough_slope:
                    return {
                        'detected': True,
                        'type': 'Falling Wedge',
                        'confidence': 0.65,
                        'pattern_completion': 60
                    }
                elif peak_slope > 0 and trough_slope > 0 and peak_slope > trough_slope:
                    return {
                        'detected': True,
                        'type': 'Rising Wedge',
                        'confidence': 0.65,
                        'pattern_completion': 60
                    }
            
            return {'detected': False}
            
        except:
            return {'detected': False}
    
    def _detect_channel_pattern(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ì±„ë„ íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values[-20:]
            
            if len(prices) < 15:
                return {'detected': False}
            
            peaks, _ = find_peaks(prices, distance=3)
            troughs, _ = find_peaks(-prices, distance=3)
            
            if len(peaks) >= 2 and len(troughs) >= 2:
                peak_slope = np.polyfit(peaks[-2:], [prices[p] for p in peaks[-2:]], 1)[0]
                trough_slope = np.polyfit(troughs[-2:], [prices[t] for t in troughs[-2:]], 1)[0]
                
                slope_diff = abs(peak_slope - trough_slope)
                
                if slope_diff < 0.05:  # í‰í–‰ì„  ì¡°ê±´
                    if abs(peak_slope) < 0.02:
                        channel_type = 'Horizontal Channel'
                    elif peak_slope > 0:
                        channel_type = 'Rising Channel'
                    else:
                        channel_type = 'Falling Channel'
                    
                    return {
                        'detected': True,
                        'type': channel_type,
                        'confidence': 0.70,
                        'pattern_completion': 75
                    }
            
            return {'detected': False}
            
        except:
            return {'detected': False}
    
    def _detect_flag_pennant(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í”Œë˜ê·¸/í˜ë„ŒíŠ¸ íŒ¨í„´ ê°ì§€"""
        try:
            prices = data['Close'].values[-8:]
            volumes = data['Volume'].values[-8:] if 'Volume' in data.columns else None
            
            if len(prices) < 6:
                return {'detected': False}
            
            early_volatility = np.std(prices[:4])
            late_volatility = np.std(prices[-4:])
            
            if late_volatility < early_volatility * 0.7:
                volume_decreasing = True
                if volumes is not None:
                    early_volume = np.mean(volumes[:4])
                    late_volume = np.mean(volumes[-4:])
                    volume_decreasing = late_volume < early_volume
                
                if volume_decreasing:
                    return {
                        'detected': True,
                        'type': 'Flag/Pennant',
                        'confidence': 0.60,
                        'pattern_completion': 70
                    }
            
            return {'detected': False}
            
        except:
            return {'detected': False}
    
    def _calculate_advanced_indicators(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        try:
            indicators = {}
            
            # Ichimoku Cloud
            indicators['ichimoku'] = self._calculate_ichimoku(data)
            
            # Parabolic SAR
            indicators['parabolic_sar'] = self._calculate_parabolic_sar(data)
            
            # Average True Range (ATR)
            indicators['atr'] = self._calculate_atr(data)
            
            # Commodity Channel Index (CCI)
            indicators['cci'] = self._calculate_cci(data)
            
            return indicators
            
        except Exception as e:
            logger.warning(f"ê³ ê¸‰ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_ichimoku(self, data: pd.DataFrame) -> Dict[str, float]:
        """Ichimoku Cloud ê³„ì‚°"""
        try:
            tenkan_sen = (data['High'].rolling(9).max() + data['Low'].rolling(9).min()) / 2
            kijun_sen = (data['High'].rolling(26).max() + data['Low'].rolling(26).min()) / 2
            senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(26)
            senkou_span_b = ((data['High'].rolling(52).max() + data['Low'].rolling(52).min()) / 2).shift(26)
            
            return {
                'tenkan_sen': tenkan_sen.iloc[-1] if not tenkan_sen.empty else 0,
                'kijun_sen': kijun_sen.iloc[-1] if not kijun_sen.empty else 0,
                'senkou_span_a': senkou_span_a.iloc[-1] if not senkou_span_a.empty else 0,
                'senkou_span_b': senkou_span_b.iloc[-1] if not senkou_span_b.empty else 0
            }
        except:
            return {}
    
    def _calculate_parabolic_sar(self, data: pd.DataFrame) -> float:
        """Parabolic SAR ê³„ì‚°"""
        try:
            high = data['High'].values
            low = data['Low'].values
            close = data['Close'].values
            
            if len(close) < 5:
                return close[-1]
            
            if close[-1] > close[-5]:
                sar = min(low[-5:])
            else:
                sar = max(high[-5:])
            
            return sar
        except:
            return 0
    
    def _calculate_atr(self, data: pd.DataFrame, period: int = 14) -> float:
        """Average True Range ê³„ì‚°"""
        try:
            high = data['High']
            low = data['Low']
            close = data['Close']
            
            tr1 = high - low
            tr2 = abs(high - close.shift())
            tr3 = abs(low - close.shift())
            
            true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = true_range.rolling(period).mean()
            
            return atr.iloc[-1] if not atr.empty else 0
        except:
            return 0
    
    def _calculate_cci(self, data: pd.DataFrame, period: int = 20) -> float:
        """Commodity Channel Index ê³„ì‚°"""
        try:
            typical_price = (data['High'] + data['Low'] + data['Close']) / 3
            sma = typical_price.rolling(period).mean()
            mean_deviation = typical_price.rolling(period).apply(lambda x: np.mean(np.abs(x - x.mean())))
            
            cci = (typical_price - sma) / (0.015 * mean_deviation)
            
            return cci.iloc[-1] if not cci.empty else 0
        except:
            return 0
    
    def create_advanced_chart(self, data: pd.DataFrame, analysis_results: Dict[str, Any]) -> go.Figure:
        """ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
        try:
            fig = make_subplots(
                rows=4, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.03,
                subplot_titles=(
                    'Price & Chart Patterns', 
                    'Elliott Wave Analysis', 
                    'Fibonacci Levels',
                    'Pattern Detection'
                ),
                row_heights=[0.5, 0.2, 0.2, 0.1]
            )
            
            # ë©”ì¸ ê°€ê²© ì°¨íŠ¸ (ìº”ë“¤ìŠ¤í‹±)
            fig.add_trace(
                go.Candlestick(
                    x=data.index,
                    open=data['Open'],
                    high=data['High'],
                    low=data['Low'],
                    close=data['Close'],
                    name='Price',
                    increasing_line_color='green',
                    decreasing_line_color='red'
                ),
                row=1, col=1
            )
            
            # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ì¶”ê°€
            fib_data = analysis_results.get('fibonacci_levels', {}).get('primary', {})
            if fib_data and 'fibonacci_levels' in fib_data:
                for level_name, level_value in fib_data['fibonacci_levels'].items():
                    level_pct = level_name.split('_')[1]
                    fig.add_hline(
                        y=level_value,
                        line_dash="dash",
                        line_color="gold",
                        annotation_text=f"Fib {level_pct}",
                        annotation_position="bottom right",
                        row=1, col=1
                    )
            
            # ì°¨íŠ¸ íŒ¨í„´ í‘œì‹œ
            patterns = analysis_results.get('chart_patterns', {})
            pattern_y_position = data['Close'].iloc[-1]
            
            for pattern_name, pattern_data in patterns.items():
                if pattern_data.get('detected'):
                    pattern_type = pattern_data.get('type', 'Unknown')
                    confidence = pattern_data.get('confidence', 0)
                    
                    fig.add_annotation(
                        x=data.index[-1],
                        y=pattern_y_position,
                        text=f"{pattern_type}<br>({confidence:.0%})",
                        showarrow=True,
                        arrowhead=2,
                        arrowcolor="blue",
                        bgcolor="lightblue",
                        bordercolor="blue",
                        row=1, col=1
                    )
                    pattern_y_position *= 1.02
            
            # ì—˜ë¦¬ì–´íŠ¸ íŒŒë™ ì •ë³´
            elliott = analysis_results.get('elliott_wave', {})
            if elliott and elliott.get('wave_count', 0) > 0:
                fig.add_trace(
                    go.Scatter(
                        x=[data.index[-1]],
                        y=[elliott.get('completion_percentage', 0)],
                        mode='markers+text',
                        text=[f"Wave: {elliott.get('current_wave', 'N/A')}<br>ì™„ì„±ë„: {elliott.get('completion_percentage', 0):.0f}%"],
                        name='Elliott Wave',
                        marker=dict(size=10, color='purple')
                    ),
                    row=2, col=1
                )
                
                next_target = elliott.get('next_target', 0)
                if next_target > 0:
                    fig.add_hline(
                        y=next_target,
                        line_dash="dot",
                        line_color="purple",
                        annotation_text=f"ëª©í‘œ: ${next_target:.2f}",
                        row=1, col=1
                    )
            
            fig.update_layout(
                title="Advanced Technical Analysis Dashboard",
                xaxis_rangeslider_visible=False,
                height=900,
                showlegend=True
            )
            
            return fig
            
        except Exception as e:
            logger.error(f"ê³ ê¸‰ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì°¨íŠ¸ ë°˜í™˜
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=data.index,
                y=data['Close'],
                mode='lines',
                name='Price'
            ))
            fig.update_layout(title="Basic Price Chart", height=400)
            return fig
