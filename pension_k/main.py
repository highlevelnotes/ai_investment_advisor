# main.py
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import os
import pickle
import json
from pathlib import Path

warnings.filterwarnings('ignore')

# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • ë¡œë“œ
from config import Config, validate_config, get_api_status, APP_CONFIG
from data_collector import DataCollector
from ai_analyzer import AIAnalyzer
from portfolio_optimizer import PortfolioOptimizer
from visualization import create_portfolio_pie_chart, create_performance_chart
from utils import calculate_portfolio_performance, format_currency

# ìºì‹œ ì„¤ì •
CACHE_DIR = 'cache'
ETF_CACHE_FILE = os.path.join(CACHE_DIR, 'etf_data_cache.pkl')
ECONOMIC_CACHE_FILE = os.path.join(CACHE_DIR, 'economic_data_cache.pkl')
MARKET_CACHE_FILE = os.path.join(CACHE_DIR, 'market_data_cache.pkl')
CACHE_EXPIRY_HOURS = 6  # 6ì‹œê°„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ 

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=APP_CONFIG['TITLE'],
    page_icon=APP_CONFIG['PAGE_ICON'],
    layout=APP_CONFIG['LAYOUT']
)

def ensure_cache_dir():
    """ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def is_cache_valid(cache_file, expiry_hours=CACHE_EXPIRY_HOURS):
    """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
    if not os.path.exists(cache_file):
        return False
    
    file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
    current_time = datetime.now()
    
    return (current_time - file_time).total_seconds() < expiry_hours * 3600

def load_cached_data(cache_file, data_type="ë°ì´í„°"):
    """ìºì‹œ ë°ì´í„° ë¡œë“œ"""
    if not is_cache_valid(cache_file):
        return None
    
    try:
        with open(cache_file, 'rb') as f:
            data = pickle.load(f)
        print(f"âœ… {data_type} ìºì‹œ ë¡œë“œ ì„±ê³µ")
        return data
    except Exception as e:
        print(f"âŒ {data_type} ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def save_cached_data(data, cache_file, data_type="ë°ì´í„°"):
    """ìºì‹œ ë°ì´í„° ì €ì¥"""
    ensure_cache_dir()
    try:
        with open(cache_file, 'wb') as f:
            pickle.dump(data, f)
        print(f"âœ… {data_type} ìºì‹œ ì €ì¥ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ {data_type} ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

def get_cache_info():
    """ìºì‹œ ì •ë³´ ì¡°íšŒ"""
    cache_info = {}
    
    for cache_file, data_type in [
        (ETF_CACHE_FILE, "ETF ë°ì´í„°"),
        (ECONOMIC_CACHE_FILE, "ê²½ì œì§€í‘œ"),
        (MARKET_CACHE_FILE, "ì‹œì¥ ë°ì´í„°")
    ]:
        if os.path.exists(cache_file):
            file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            is_valid = is_cache_valid(cache_file)
            cache_info[data_type] = {
                'last_updated': file_time.strftime('%Y-%m-%d %H:%M:%S'),
                'is_valid': is_valid,
                'status': 'ìœ íš¨' if is_valid else 'ë§Œë£Œë¨'
            }
        else:
            cache_info[data_type] = {
                'last_updated': 'ì—†ìŒ',
                'is_valid': False,
                'status': 'ìºì‹œ ì—†ìŒ'
            }
    
    return cache_info

def load_or_collect_etf_data():
    """ETF ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìˆ˜ì§‘ (ìºì‹± ì ìš©)"""
    # ìºì‹œ ì‹œë„
    cached_data = load_cached_data(ETF_CACHE_FILE, "ETF ë°ì´í„°")
    if cached_data is not None:
        return cached_data
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ë§Œë£Œëœ ê²½ìš° ìƒˆë¡œ ìˆ˜ì§‘
    with st.spinner('ğŸ“Š ETF ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ìµœì´ˆ ì‹¤í–‰ì‹œ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)'):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        data_collector = DataCollector()
        
        # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜
        def progress_callback(current, total, message):
            progress = current / total
            progress_bar.progress(progress)
            status_text.text(f"{message} ({current}/{total})")
        
        etf_data = data_collector.get_etf_data(progress_callback=progress_callback)
        
        progress_bar.empty()
        status_text.empty()
        
        # ìºì‹œ ì €ì¥
        save_cached_data(etf_data, ETF_CACHE_FILE, "ETF ë°ì´í„°")
        
        return etf_data

def load_or_collect_economic_data():
    """ê²½ì œì§€í‘œ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìˆ˜ì§‘ (ìºì‹± ì ìš©)"""
    cached_data = load_cached_data(ECONOMIC_CACHE_FILE, "ê²½ì œì§€í‘œ")
    if cached_data is not None:
        return cached_data
    
    with st.spinner('ğŸ“ˆ ê²½ì œì§€í‘œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
        data_collector = DataCollector()
        economic_data = data_collector.get_economic_indicators()
        save_cached_data(economic_data, ECONOMIC_CACHE_FILE, "ê²½ì œì§€í‘œ")
        return economic_data

def load_or_collect_market_data():
    """ì‹œì¥ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìˆ˜ì§‘ (ìºì‹± ì ìš©)"""
    cached_data = load_cached_data(MARKET_CACHE_FILE, "ì‹œì¥ ë°ì´í„°")
    if cached_data is not None:
        return cached_data
    
    with st.spinner('ğŸ“‰ ì‹œì¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
        data_collector = DataCollector()
        market_data = data_collector.get_market_data()
        save_cached_data(market_data, MARKET_CACHE_FILE, "ì‹œì¥ ë°ì´í„°")
        return market_data

def clear_cache():
    """ìºì‹œ ì‚­ì œ"""
    cache_files = [ETF_CACHE_FILE, ECONOMIC_CACHE_FILE, MARKET_CACHE_FILE]
    cleared_count = 0
    
    for cache_file in cache_files:
        if os.path.exists(cache_file):
            try:
                os.remove(cache_file)
                cleared_count += 1
            except Exception as e:
                print(f"ìºì‹œ ì‚­ì œ ì‹¤íŒ¨ {cache_file}: {e}")
    
    return cleared_count

def main():
    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    config_valid = validate_config()
    api_status = get_api_status()
    
    # í—¤ë”
    st.title(APP_CONFIG['TITLE'])
    st.markdown(f"*{APP_CONFIG['DESCRIPTION']}*")
    
    # í”„ë¡œì íŠ¸ ëª©ì  ì„¤ëª…
    st.info("""
    ğŸ‡°ğŸ‡· **AI ê¸°ë°˜ êµ­ë‚´ ETF í‡´ì§ì—°ê¸ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹œìŠ¤í…œ**
    
    HyperClova X AIê°€ ë§¤í¬ë¡œ ê²½ì œ ìƒí™©ì„ ì‹¤ì‹œê°„ ë¶„ì„í•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• ë‹¤ì¤‘ ETF í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ìˆœìˆ˜ êµ­ë‚´ ETFë§Œì„ í™œìš©í•˜ì—¬ êµ­ë‚´ ìë³¸ì‹œì¥ í™œì„±í™”ì— ê¸°ì—¬í•©ë‹ˆë‹¤.
    
    âœ… AI ê¸°ë°˜ ì‹œì¥ ë¶„ì„  âœ… ë‹¤ì¤‘ ETF ë¶„ì‚°íˆ¬ì  âœ… ì‹¤ì‹œê°„ ì„±ê³¼ ê³„ì‚°  âœ… êµ­ë‚´ ETF íŠ¹í™”
    """)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ë° ìºì‹œ ì •ë³´
    with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ ë° ìºì‹œ ì •ë³´", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**API ì—°ê²° ìƒíƒœ**")
            status_icon = "âœ…" if api_status['ecos'] else "âŒ"
            st.write(f"{status_icon} ECOS API")
            status_icon = "âœ…" if api_status['hyperclova_x'] else "âŒ"
            st.write(f"{status_icon} HyperClova X API")
            status_icon = "âœ…" if api_status['pykrx'] else "âŒ"
            st.write(f"{status_icon} PyKRX")
        
        with col2:
            st.markdown("**ìºì‹œ ìƒíƒœ**")
            cache_info = get_cache_info()
            for data_type, info in cache_info.items():
                status_color = "ğŸŸ¢" if info['is_valid'] else "ğŸ”´"
                st.write(f"{status_color} {data_type}: {info['status']}")
                if info['last_updated'] != 'ì—†ìŒ':
                    st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {info['last_updated']}")
        
        # ìºì‹œ ê´€ë¦¬ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ ìºì‹œ ìƒˆë¡œê³ ì¹¨"):
                cleared_count = clear_cache()
                st.success(f"{cleared_count}ê°œ ìºì‹œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
        
        with col2:
            if st.button("ğŸ“Š ë°ì´í„° ê°•ì œ ì—…ë°ì´íŠ¸"):
                clear_cache()
                st.rerun()
        
        if not config_valid:
            st.warning("ì¼ë¶€ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” - ì‚¬ìš©ì í”„ë¡œí•„
    st.sidebar.header("ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„")
    
    user_profile = {
        'age': st.sidebar.slider("ë‚˜ì´", 20, 70, 35),
        'risk_tolerance': st.sidebar.selectbox(
            "íˆ¬ìì„±í–¥", 
            ['ì•ˆì •í˜•', 'ì•ˆì •ì¶”êµ¬í˜•', 'ìœ„í—˜ì¤‘ë¦½í˜•', 'ì ê·¹íˆ¬ìí˜•']
        ),
        'investment_period': st.sidebar.slider("íˆ¬ìê¸°ê°„ (ë…„)", 5, 40, 20),
        'current_assets': st.sidebar.number_input(
            "í˜„ì¬ ìì‚° (ë§Œì›)", 
            min_value=0, 
            max_value=100000, 
            value=1000,
            step=100
        ) * 10000,
        'monthly_contribution': st.sidebar.number_input(
            "ì›” ë‚©ì…ì•¡ (ë§Œì›)", 
            min_value=0, 
            max_value=1000, 
            value=50,
            step=10
        ) * 10000
    }
    
    # ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
    if 'etf_data' not in st.session_state:
        st.session_state.etf_data = load_or_collect_etf_data()
    
    if 'economic_data' not in st.session_state:
        st.session_state.economic_data = load_or_collect_economic_data()
    
    if 'market_data' not in st.session_state:
        st.session_state.market_data = load_or_collect_market_data()
    
    # ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        etf_count = sum(len(etfs) for etfs in st.session_state.etf_data.values())
        st.metric("ë¡œë“œëœ ETF ìˆ˜", etf_count)
    with col2:
        economic_count = len(st.session_state.economic_data)
        st.metric("ê²½ì œì§€í‘œ ìˆ˜", economic_count)
    with col3:
        market_status = "ì •ìƒ" if st.session_state.market_data else "ì˜¤ë¥˜"
        st.metric("ì‹œì¥ ë°ì´í„°", market_status)
    
    # ë©”ì¸ AI ë¶„ì„ ë° í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±
    st.header("ğŸ¤– AI ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë° ë‹¤ì¤‘ ETF í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”")
    
    # AI ë¶„ì„ ì‹¤í–‰
    if st.button("ğŸš€ AI ì¢…í•© ë¶„ì„ ë° ë‹¤ì¤‘ ETF í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±", type="primary", use_container_width=True):
        ai_analyzer = AIAnalyzer()
        
        with st.spinner("AIê°€ ì‹œì¥ì„ ë¶„ì„í•˜ê³  ë‹¤ì¤‘ ETF ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ì¢…í•© ë¶„ì„ ì‹¤í–‰
            comprehensive_result = ai_analyzer.comprehensive_market_analysis(
                st.session_state.economic_data,
                st.session_state.etf_data,
                user_profile
            )
            
            if comprehensive_result:
                st.session_state.ai_analysis_result = comprehensive_result
                
                # ê²°ê³¼ í‘œì‹œ
                analysis = comprehensive_result['analysis']
                portfolio = comprehensive_result['portfolio']
                
                # 1. ì‹œì¥ ë¶„ì„ ê²°ê³¼
                st.subheader("ğŸ“Š AI ì‹œì¥ ë¶„ì„")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**ğŸ›ï¸ ë§¤í¬ë¡œ ê²½ì œ ë¶„ì„**")
                    st.write(analysis['macro_analysis'])
                    
                    st.markdown("**ğŸ“ˆ ETF ì‹œì¥ ë™í–¥**")
                    st.write(analysis['market_trends'])
                
                with col2:
                    st.markdown("**ğŸ¯ íˆ¬ì ì „ëµ**")
                    st.write(analysis['investment_strategy'])
                    
                    st.markdown("**âš ï¸ ë¦¬ìŠ¤í¬ ìš”ì¸**")
                    st.write(analysis['risk_factors'])
                
                # 2. ë‹¤ì¤‘ ETF í¬íŠ¸í´ë¦¬ì˜¤ ê²°ê³¼
                st.subheader("ğŸ’¼ AI ì¶”ì²œ ë‹¤ì¤‘ ETF í¬íŠ¸í´ë¦¬ì˜¤")
                
                weights = portfolio['weights']
                
                if weights:
                    # í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ ETF ìˆ˜", portfolio.get('etf_count', len(weights)))
                    with col2:
                        st.metric("ë¶„ì‚°íˆ¬ì ì „ëµ", "ë‹¤ì¤‘ ETF ì¡°í•©")
                    with col3:
                        category_count = len(portfolio.get('category_distribution', {}).get('category_weights', {}))
                        st.metric("ìì‚°êµ° ìˆ˜", category_count)
                    
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown("**ğŸ“Š ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±**")
                        pie_chart = create_portfolio_pie_chart(weights)
                        st.plotly_chart(pie_chart, use_container_width=True)
                    
                    with col2:
                        st.markdown("**ğŸ“‹ ìƒì„¸ êµ¬ì„±**")
                        weights_df = pd.DataFrame([
                            {
                                'ETFëª…': name,
                                'ë¹„ì¤‘': f"{weight*100:.1f}%",
                                'íˆ¬ìê¸ˆì•¡': format_currency(weight * user_profile['current_assets'])
                            }
                            for name, weight in weights.items()
                        ])
                        st.dataframe(weights_df, use_container_width=True)
                    
                    # 3. ìì‚°êµ°ë³„ ë¶„í¬ í‘œì‹œ
                    if 'category_distribution' in portfolio:
                        st.subheader("ğŸ“ˆ ìì‚°êµ°ë³„ ETF ë¶„í¬")
                        
                        category_dist = portfolio['category_distribution']
                        
                        for category, category_weight in category_dist.get('category_weights', {}).items():
                            if category_weight > 0:
                                with st.expander(f"{category} ({category_weight*100:.1f}%)", expanded=False):
                                    category_etfs = category_dist.get('etfs_by_category', {}).get(category, [])
                                    
                                    for etf_info in category_etfs:
                                        col1, col2 = st.columns([3, 1])
                                        with col1:
                                            st.write(f"â€¢ {etf_info['name']}")
                                        with col2:
                                            st.write(f"{etf_info['weight']*100:.1f}%")
                    
                    # 4. ì‹¤ì œ ì„±ê³¼ ê³„ì‚°
                    st.subheader("ğŸ“ˆ ì˜ˆìƒ ì„±ê³¼ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)")
                    
                    with st.spinner("ì‹¤ì œ ETF ë°ì´í„°ë¡œ ì„±ê³¼ë¥¼ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        performance = calculate_portfolio_performance(
                            weights, 
                            st.session_state.etf_data
                        )
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            expected_return = performance['expected_return'] * 100
                            st.metric(
                                "ì—°í™˜ì‚° ìˆ˜ìµë¥ ", 
                                f"{expected_return:.2f}%",
                                help="ì‹¤ì œ ETF ê³¼ê±° ìˆ˜ìµë¥  ê¸°ë°˜"
                            )
                        
                        with col2:
                            volatility = performance['volatility'] * 100
                            st.metric(
                                "ì—°í™˜ì‚° ë³€ë™ì„±", 
                                f"{volatility:.2f}%",
                                help="ë‹¤ì¤‘ ETF ë¶„ì‚°íš¨ê³¼ ë°˜ì˜"
                            )
                        
                        with col3:
                            sharpe_ratio = performance['sharpe_ratio']
                            st.metric(
                                "ìƒ¤í”„ ë¹„ìœ¨", 
                                f"{sharpe_ratio:.3f}",
                                help="ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµë¥ "
                            )
                        
                        with col4:
                            max_drawdown = performance['max_drawdown'] * 100
                            st.metric(
                                "ìµœëŒ€ ë‚™í­", 
                                f"{max_drawdown:.2f}%",
                                help="ë¶„ì‚°íˆ¬ì íš¨ê³¼ë¡œ ë‚™í­ ê°ì†Œ"
                            )
                    
                    # 5. ë¶„ì‚°íˆ¬ì íš¨ê³¼ ë¶„ì„
                    with st.expander("ğŸ” ë¶„ì‚°íˆ¬ì íš¨ê³¼ ë¶„ì„", expanded=False):
                        st.markdown("**ë‹¤ì¤‘ ETF ë¶„ì‚°íˆ¬ì ì „ëµ:**")
                        st.write(portfolio.get('diversification_strategy', 'ìì‚°êµ° ë‚´ì™¸ ì´ì¤‘ ë¶„ì‚°íˆ¬ì'))
                        
                        st.markdown("**ë°°ë¶„ ê·¼ê±°:**")
                        st.write(portfolio.get('allocation_reasoning', 'AI ê¸°ë°˜ ìµœì  ë°°ë¶„'))
                        
                        st.markdown("**ë¶„ì‚°íˆ¬ì ì¥ì :**")
                        st.write("â€¢ ê° ìì‚°êµ° ë‚´ì—ì„œ 2-3ê°œ ETF ì¡°í•©ìœ¼ë¡œ ì´ì¤‘ ë¶„ì‚°íš¨ê³¼")
                        st.write("â€¢ ê°œë³„ ETF ë¦¬ìŠ¤í¬ ìµœì†Œí™”")
                        st.write("â€¢ ì‹œì¥ ë³€ë™ì„±ì— ëŒ€í•œ ì•ˆì •ì„± í™•ë³´")
                        st.write("â€¢ ìƒê´€ê´€ê³„ê°€ ë‚®ì€ ETF ì¡°í•©ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ íš¨ìœ¨ì„± ì¦ëŒ€")
                        
                        st.markdown("**ë°ì´í„° ì†ŒìŠ¤:**")
                        st.write(comprehensive_result['source'])
                        
                        if performance.get('data_points', 0) > 0:
                            st.success(f"âœ… ì‹¤ì œ ETF ë°ì´í„° {performance['data_points']}ì¼ ê¸°ë°˜ ê³„ì‚°")
                        else:
                            st.warning("âš ï¸ ìƒ˜í”Œ ë°ì´í„° ê¸°ë°˜ ê³„ì‚°")
                
                else:
                    st.error("í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            else:
                st.error("AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    # ì´ì „ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if 'ai_analysis_result' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“‹ ìµœê·¼ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        
        result = st.session_state.ai_analysis_result
        portfolio = result['portfolio']
        
        if portfolio['weights']:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("í¬íŠ¸í´ë¦¬ì˜¤ ETF ìˆ˜", len(portfolio['weights']))
            
            with col2:
                st.metric("ë¶„ì‚°íˆ¬ì ì „ëµ", "ë‹¤ì¤‘ ETF")
            
            with col3:
                category_count = len(portfolio.get('category_distribution', {}).get('category_weights', {}))
                st.metric("ìì‚°êµ° ìˆ˜", category_count)
            
            with col4:
                st.metric("ë°ì´í„° ì†ŒìŠ¤", result.get('source', 'unknown'))
            
            # ê°„ë‹¨í•œ í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½
            with st.expander("í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„¸ êµ¬ì„±", expanded=False):
                for etf_name, weight in portfolio['weights'].items():
                    st.write(f"â€¢ {etf_name}: {weight*100:.1f}%")

def calculate_expected_retirement_assets(user_profile):
    """ì˜ˆìƒ ì€í‡´ìì‚° ê³„ì‚°"""
    current_assets = user_profile['current_assets']
    monthly_contribution = user_profile['monthly_contribution']
    investment_period = user_profile['investment_period']
    
    # ê°€ì •: ì—° 6% ìˆ˜ìµë¥ 
    annual_return = 0.06
    monthly_return = annual_return / 12
    
    # ë³µë¦¬ ê³„ì‚°
    future_value_current = current_assets * (1 + annual_return) ** investment_period
    future_value_monthly = monthly_contribution * (((1 + monthly_return) ** (investment_period * 12) - 1) / monthly_return)
    
    return future_value_current + future_value_monthly

if __name__ == "__main__":
    main()
