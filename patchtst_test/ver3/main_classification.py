import os
import torch
import warnings
import numpy as np
warnings.filterwarnings('ignore')

from data_collector_classification import BitcoinClassificationDataCollector
from classification_preprocessor import BitcoinClassificationPreprocessor
from patchtst_classification import PatchTSTClassification
from classification_trainer import ClassificationTrainer
from classification_evaluator import ClassificationEvaluator

def main():
    print("=== ë¹„íŠ¸ì½”ì¸ PatchTST ì´ì§„ ë¶„ë¥˜ ì‹œìŠ¤í…œ ===")
    print("ëª©í‘œ: 1ì‹œê°„ í›„ ê°€ê²© ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡")
    
    # 1. ë¶„ë¥˜ìš© ë°ì´í„° ìˆ˜ì§‘
    print("\n1. ë¶„ë¥˜ìš© ë°ì´í„° ìˆ˜ì§‘...")
    collector = BitcoinClassificationDataCollector()
    train_data, test_data = collector.collect_and_prepare_data()
    
    if train_data is None or test_data is None:
        print("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")
        return
    
    # ë°ì´í„° ìƒíƒœ í™•ì¸
    print(f"\n=== ë¶„ë¥˜ ë°ì´í„° ìƒíƒœ ===")
    print(f"í•™ìŠµ ë°ì´í„°: {len(train_data)}ì‹œê°„")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ì‹œê°„")
    print(f"íŠ¹ì„± ìˆ˜: {len(train_data.columns) - 1}ê°œ (Label ì œì™¸)")
    
    # 2. ë¶„ë¥˜ìš© ë°ì´í„° ì „ì²˜ë¦¬
    print("\n2. ë¶„ë¥˜ìš© ë°ì´í„° ì „ì²˜ë¦¬...")
    preprocessor = BitcoinClassificationPreprocessor()
    
    # ë¶„ë¥˜ì— ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    sequence_length = 168  # 1ì£¼ì¼ (168ì‹œê°„)
    batch_size = 64
    
    # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¡°ì •
    if len(test_data) < sequence_length:
        sequence_length = max(72, len(test_data) // 3)
        print(f"ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ {sequence_length}ì‹œê°„ìœ¼ë¡œ ì¡°ì •")
    
    print(f"ì„¤ì •: ì‹œí€€ìŠ¤={sequence_length}ì‹œê°„, ë°°ì¹˜={batch_size}")
    
    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
    try:
        train_loader, val_loader, num_features = preprocessor.prepare_train_data(
            train_data, sequence_length, batch_size
        )
        print(f"íŠ¹ì„± ìˆ˜: {num_features}ê°œ")
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {preprocessor.class_weights}")
    except Exception as e:
        print(f"í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return
    
    # 3. ë¶„ë¥˜ìš© ëª¨ë¸ ì„¤ì •
    print("\n3. ë¶„ë¥˜ìš© PatchTST ëª¨ë¸ ì´ˆê¸°í™”...")
    
    model_config = {
        'sequence_length': sequence_length,
        'num_features': num_features,
        'num_classes': 2,        # ì´ì§„ ë¶„ë¥˜ (ìƒìŠ¹/í•˜ë½)
        'patch_length': 24,      # 24ì‹œê°„ íŒ¨ì¹˜
        'patch_stride': 12,      # 12ì‹œê°„ ìŠ¤íŠ¸ë¼ì´ë“œ
        'd_model': 256,
        'num_heads': 8,
        'num_layers': 4,
        'ffn_dim': 512,
        'dropout': 0.1
    }
    
    model = PatchTSTClassification(model_config)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ë¶„ë¥˜ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
    
    # 4. ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
    print("\n4. ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ...")
    trainer = ClassificationTrainer(model, class_weights=preprocessor.class_weights)
    trainer.train(train_loader, val_loader, epochs=100)
    
    # 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    print("\n5. ë¶„ë¥˜ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„...")
    test_sequences, test_labels = preprocessor.prepare_test_data(
        test_data, sequence_length
    )
    
    print(f"í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤: {test_sequences.shape}")
    print(f"í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”: {test_labels.shape}")
    print(f"í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ë¶„í¬: í•˜ë½={np.sum(test_labels==0)}, ìƒìŠ¹={np.sum(test_labels==1)}")
    
    if len(test_sequences) == 0:
        print("í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 6. ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
    print("\n6. ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€...")
    trainer.load_model('models/classification/best_model.pth')
    evaluator = ClassificationEvaluator(trainer.model)
    
    metrics, results_df = evaluator.evaluate_classification(test_sequences, test_labels)
    
    # 7. ê²°ê³¼ ë¶„ì„
    print("\n=== ìµœì¢… ë¶„ë¥˜ ì„±ëŠ¥ ë¶„ì„ ===")
    
    accuracy = metrics['accuracy']
    f1 = metrics['f1']
    auc = metrics['auc']
    
    print(f"ğŸ¯ ì „ì²´ ì •í™•ë„: {accuracy:.1%}")
    print(f"ğŸ“Š F1-Score: {f1:.4f}")
    print(f"ğŸ“ˆ ROC AUC: {auc:.4f}")
    
    # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
    if accuracy > 0.60 and auc > 0.65:
        print("ğŸŸ¢ ìš°ìˆ˜: ì‹¤ìš©ì ì¸ ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ì„±ëŠ¥!")
    elif accuracy > 0.55 and auc > 0.60:
        print("ğŸŸ¡ ì–‘í˜¸: ê¸°ë³¸ì ì¸ ì˜ˆì¸¡ ì„±ëŠ¥ í™•ë³´")
    elif accuracy > 0.50:
        print("ğŸŸ  ë³´í†µ: ëœë¤ë³´ë‹¤ëŠ” ë‚˜ì€ ì„±ëŠ¥")
    else:
        print("ğŸ”´ ë¶€ì¡±: ì„±ëŠ¥ ê°œì„  í•„ìš”")
    
    # ì‹¤ìš©ì„± ë¶„ì„
    print(f"\n=== ì‹¤ìš©ì„± ë¶„ì„ ===")
    correct_predictions = np.sum(results_df['Correct'])
    total_predictions = len(results_df)
    
    print(f"ì´ ì˜ˆì¸¡ íšŸìˆ˜: {total_predictions:,}íšŒ")
    print(f"ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions:,}íšŒ")
    print(f"ì˜ëª»ëœ ì˜ˆì¸¡: {total_predictions - correct_predictions:,}íšŒ")
    
    # ìˆ˜ìµì„± ì‹œë®¬ë ˆì´ì…˜ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    up_predictions = results_df['Predicted'] == 1
    actual_up = results_df['Actual'] == 1
    
    true_positives = np.sum(up_predictions & actual_up)
    false_positives = np.sum(up_predictions & ~actual_up)
    
    if np.sum(up_predictions) > 0:
        precision_up = true_positives / np.sum(up_predictions)
        print(f"\nìƒìŠ¹ ì˜ˆì¸¡ ì •ë°€ë„: {precision_up:.1%}")
        print(f"ìƒìŠ¹ ì˜ˆì¸¡ ì‹œ ì‹¤ì œ ìƒìŠ¹ í™•ë¥ : {precision_up:.1%}")
    
    print(f"\nì¶œë ¥ íŒŒì¼:")
    print(f"- models/classification/best_model.pth (í•™ìŠµëœ ë¶„ë¥˜ ëª¨ë¸)")
    print(f"- results/classification/predictions.csv (ì˜ˆì¸¡ ê²°ê³¼)")
    print(f"- results/classification/metrics.json (ì„±ëŠ¥ ì§€í‘œ)")
    print(f"- results/classification/plots/classification_results.png (ì‹œê°í™”)")

if __name__ == "__main__":
    main()
